{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia de Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo os dados brutos e concatenando-os em um único dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250889, 30)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '../data/raw/' \n",
    "\n",
    "dados_2021 = pd.read_csv(base_path + '2021.csv', encoding='latin-1', sep=';')\n",
    "dados_2022 = pd.read_csv(base_path + '2022.csv', sep=',')\n",
    "dados_2023 = pd.read_csv(base_path + '2023.csv', encoding='latin-1', sep=';')\n",
    "dados_2024 = pd.read_csv(base_path + '2024.csv', sep=',')\n",
    "\n",
    "dados = pd.concat([dados_2021, dados_2022, dados_2023, dados_2024], axis=0, ignore_index=True)\n",
    "\n",
    "dados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na análise exploratória, foram indentificadas colunas em que haviam dados nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uop                       219\n",
       "delegacia                  85\n",
       "regional                   23\n",
       "classificacao_acidente      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulos = dados.isnull().sum().sort_values(ascending=False)\n",
    "nulos[nulos>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconhecendo os dados dessas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    UOP01-DEL05-SP\n",
       " 1    UOP01-DEL01-AM\n",
       " 2    UOP03-DEL04-CE\n",
       " 3    UOP02-DEL04-RJ\n",
       " 4    UOP04-DEL05-RJ\n",
       " Name: uop, dtype: object,\n",
       " 0    DEL05-SP\n",
       " 1    DEL01-AM\n",
       " 2    DEL04-CE\n",
       " 3    DEL04-RJ\n",
       " 4    DEL05-RJ\n",
       " Name: delegacia, dtype: object,\n",
       " 0    SPRF-SP\n",
       " 1    SPRF-AM\n",
       " 2    SPRF-CE\n",
       " 3    SPRF-RJ\n",
       " 4    SPRF-RJ\n",
       " Name: regional, dtype: object,\n",
       " 0    Com Vítimas Feridas\n",
       " 1                    NaN\n",
       " 2    Com Vítimas Feridas\n",
       " 3    Com Vítimas Feridas\n",
       " 4    Com Vítimas Feridas\n",
       " Name: classificacao_acidente, dtype: object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados['uop'].head(5), dados['delegacia'].head(5), dados['regional'].head(5), dados['classificacao_acidente'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituindo os dados faltantes pela moda das respectivas colunas, mas considerando a unidade federativa específica para a substituição assim os dados ficarão mais precisos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dados.iterrows():\n",
    "\n",
    "    if pd.isnull(row['uop']):\n",
    "\n",
    "        uf_especifica = row['uf'] \n",
    "        aux_df = dados[dados['uf'] == uf_especifica]\n",
    "        if not aux_df['uop'].mode().empty:\n",
    "            dados.at[index, 'uop'] = aux_df['uop'].mode()[0]\n",
    "\n",
    "    if pd.isnull(row['delegacia']):\n",
    "\n",
    "        uf_especifica = row['uf'] \n",
    "        aux_df = dados[dados['uf'] == uf_especifica]\n",
    "\n",
    "        if not aux_df['delegacia'].mode().empty:\n",
    "            dados.at[index, 'delegacia'] = aux_df['delegacia'].mode()[0]\n",
    "\n",
    "    if pd.isnull(row['regional']):\n",
    "\n",
    "        uf_especifica = row['uf'] \n",
    "        aux_df = dados[dados['uf'] == uf_especifica]\n",
    "\n",
    "        if not aux_df['regional'].mode().empty:\n",
    "            dados.at[index, 'regional'] = aux_df['regional'].mode()[0]\n",
    "\n",
    "    if pd.isnull(row['classificacao_acidente']):\n",
    "\n",
    "        uf_especifica = row['uf'] \n",
    "        aux_df = dados[dados['uf'] == uf_especifica]\n",
    "\n",
    "        if not aux_df['classificacao_acidente'].mode().empty:\n",
    "            dados.at[index, 'classificacao_acidente'] = aux_df['classificacao_acidente'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checando se os valores nulos foram realmente preenchidos. Como nenhuma coluna com valor nulo é impressa, não existem mais valores nulos na base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulos = dados.isnull().sum().sort_values(ascending=False)\n",
    "nulos[nulos>0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento de data/hora, mudando para o formato datetime padrão americano MM-DD-YYYY HH:MM AM/PM que geralmente são usados nos bancos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['datetime'] = pd.to_datetime(dados['data_inversa'] + ' ' + dados['horario'])\n",
    "\n",
    "# padrão americano, geralmente usado nos banco de dados\n",
    "dados['datetime'] = dados['datetime'].dt.strftime('%m-%d-%Y %I:%M %p')\n",
    "\n",
    "dados = dados.drop(columns=['data_inversa', 'horario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331730.0</td>\n",
       "      <td>01-01-2021 05:30 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>331804.0</td>\n",
       "      <td>01-01-2021 08:05 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331815.0</td>\n",
       "      <td>01-01-2021 10:10 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331823.0</td>\n",
       "      <td>01-01-2021 12:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>331843.0</td>\n",
       "      <td>01-01-2021 02:40 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250884</th>\n",
       "      <td>635554.0</td>\n",
       "      <td>09-27-2024 04:15 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250885</th>\n",
       "      <td>635630.0</td>\n",
       "      <td>09-15-2024 08:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250886</th>\n",
       "      <td>635699.0</td>\n",
       "      <td>08-13-2024 04:22 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250887</th>\n",
       "      <td>635887.0</td>\n",
       "      <td>09-21-2024 06:50 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250888</th>\n",
       "      <td>636019.0</td>\n",
       "      <td>09-15-2024 07:00 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250889 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id             datetime\n",
       "0       331730.0  01-01-2021 05:30 AM\n",
       "1       331804.0  01-01-2021 08:05 AM\n",
       "2       331815.0  01-01-2021 10:10 AM\n",
       "3       331823.0  01-01-2021 12:30 PM\n",
       "4       331843.0  01-01-2021 02:40 PM\n",
       "...          ...                  ...\n",
       "250884  635554.0  09-27-2024 04:15 PM\n",
       "250885  635630.0  09-15-2024 08:30 PM\n",
       "250886  635699.0  08-13-2024 04:22 PM\n",
       "250887  635887.0  09-21-2024 06:50 PM\n",
       "250888  636019.0  09-15-2024 07:00 PM\n",
       "\n",
       "[250889 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados[['id', 'datetime']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
